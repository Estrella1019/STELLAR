# STELLAR + Ollama æœ¬åœ°è¿è¡Œé…ç½®æŒ‡å—

## âœ… å·²å®Œæˆçš„ä¿®æ”¹

æ ¹æ®ä½ çš„ Ollama æ¨¡å‹åˆ—è¡¨ï¼ŒSTELLAR å·²ç»é…ç½®ä¸ºä½¿ç”¨ä»¥ä¸‹æœ¬åœ°æ¨¡å‹ï¼š

### 1. ç¯å¢ƒå˜é‡é…ç½® (`.env`)
```bash
# Ollama åœ°å€
OPENAI_BASE_URL=http://localhost:11434/v1

# Judge æ¨¡å‹ (ç”¨äºè¯„ä¼°æµ‹è¯•ç»“æœ)
JUDGE_MODEL=deepseek-r1:7b

# Generator æ¨¡å‹ (ç”¨äºç”Ÿæˆæ”»å‡»æç¤ºè¯)
GENERATOR_MODEL=dolphin3:latest

# SUT è¢«æµ‹ç³»ç»Ÿæ¨¡å‹
LLM_TYPE=deepseek-r1:7b
DEPLOYMENT_NAME=deepseek-r1:7b
LLM_OLLAMA=deepseek-r1:7b
```

### 2. æ¨¡å‹å®šä¹‰ (`llm/llms.py`)
å·²æ·»åŠ æœ¬åœ°æ¨¡å‹åˆ° `LLMType` æšä¸¾ï¼š
- `DEEPSEEK_R1 = "deepseek-r1:7b"`
- `DOLPHIN3 = "dolphin3"`
- `DOLPHIN_LLAMA3 = "dolphin-llama3"`
- `LLAMA3_1 = "llama3.1"`

æ‰€æœ‰è¿™äº›æ¨¡å‹å·²åŠ å…¥ `LOCAL_MODELS` é›†åˆï¼Œç¡®ä¿èµ° Ollama è°ƒç”¨è·¯å¾„ã€‚

### 3. Ollama è°ƒç”¨å‡½æ•° (`llm/call_ollama.py`)
ä½¿ç”¨ `ollama.chat()` API è¿›è¡Œæœ¬åœ°æ¨ç†ï¼Œæ”¯æŒï¼š
- æ¸©åº¦æ§åˆ¶
- Token é™åˆ¶
- Top-p é‡‡æ ·
- é‡å¤æƒ©ç½š

### 4. Judge è¯„ä¼°å¢å¼º (`examples/safety/eval.py`)
- **é—®é¢˜**: DeepSeek-R1 ä¼šè¾“å‡º `<think>...</think>` æ€è€ƒè¿‡ç¨‹
- **è§£å†³**: æ·»åŠ  `clean_deepseek_output()` å‡½æ•°æ¸…æ´—è¾“å‡º
- **å¢å¼º**: æ”¯æŒå¤šç§è¯„åˆ†æ ¼å¼ (0-1 æµ®ç‚¹æ•°ã€1-10 æ•´æ•°è¯„åˆ†)
- **å…œåº•**: è§£æå¤±è´¥æ—¶è¿”å› 0.5 è€Œä¸æ˜¯ 1.0ï¼Œé¿å…è¯¯åˆ¤

### 5. è¿è¡Œè„šæœ¬ (`run_safety_local.sh`)
é…ç½®å‚æ•°ï¼š
```bash
--sut "deepseek-r1:7b"          # è¢«æµ‹ç³»ç»Ÿ
--judge "deepseek-r1:7b"        # è¯„åˆ¤æ¨¡å‹
--fitness "deepseek-r1:7b"      # é€‚åº”åº¦è®¡ç®—
--generator "dolphin3"          # æµ‹è¯•ç”Ÿæˆ
--population_size 20            # ç§ç¾¤å¤§å°
--max_time "02:00:00"           # 2å°æ—¶è¶…æ—¶
--algorithm "nsga2"             # é—ä¼ ç®—æ³•
--use_repair                    # å¯ç”¨ä¿®å¤ç®—å­
```

---

## ğŸ”§ éœ€è¦æ‰‹åŠ¨æ£€æŸ¥çš„é…ç½®

### 1. ç¡®è®¤ Ollama æœåŠ¡è¿è¡Œ
```bash
# æ£€æŸ¥ Ollama æ˜¯å¦è¿è¡Œ
curl http://localhost:11434/api/tags

# å¦‚æœæ²¡æœ‰è¿è¡Œï¼Œå¯åŠ¨å®ƒ
ollama serve
```

### 2. éªŒè¯æ¨¡å‹å¯ç”¨æ€§
```bash
# ç¡®è®¤ deepseek-r1:7b å·²ä¸‹è½½
ollama list | grep deepseek-r1

# ç¡®è®¤ dolphin3 å·²ä¸‹è½½
ollama list | grep dolphin3

# å¦‚æœç¼ºå¤±ï¼Œæ‹‰å–æ¨¡å‹
ollama pull deepseek-r1:7b
ollama pull dolphin3:latest
```

### 3. æµ‹è¯•æ¨¡å‹è°ƒç”¨
```bash
cd /Users/panjiaying/Documents/Projects/STELLAR
python -c "
from llm.llms import pass_llm, LLMType
result = pass_llm('Hello', llm_type=LLMType.DEEPSEEK_R1)
print(result)
"
```

---

## ğŸš€ è¿è¡Œå®éªŒ

### Safety æµ‹è¯• (è®ºæ–‡ä¸­çš„ SafeQA)
```bash
cd /Users/panjiaying/Documents/Projects/STELLAR
chmod +x run_safety_local.sh
./run_safety_local.sh
```

### Navigation æµ‹è¯• (è®ºæ–‡ä¸­çš„ NaviQA)
```bash
# éœ€è¦å…ˆä¿®æ”¹ run_tests_navi.py (å‚è€ƒ run_tests_safety.py çš„ä¿®æ”¹)
python run_tests_navi.py \
    --sut "deepseek-r1:7b" \
    --judge "deepseek-r1:7b" \
    --fitness "deepseek-r1:7b" \
    --generator "dolphin3" \
    --population_size 20 \
    --algorithm "nsga2d"
```

---

## ğŸ“Š æŸ¥çœ‹ç»“æœ

ç»“æœä¼šä¿å­˜åœ¨ `results/` ç›®å½•ä¸‹ï¼Œå…³é”®æ–‡ä»¶ï¼š
- `failures_over_time.csv` - å¤±è´¥æµ‹è¯•ç”¨ä¾‹éšæ—¶é—´å˜åŒ–
- `archive.csv` - æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹å½’æ¡£
- `critical_cases.csv` - è¢«åˆ¤å®šä¸º critical çš„å¤±è´¥æ¡ˆä¾‹

---

## âš ï¸ å¸¸è§é—®é¢˜

### é—®é¢˜ 1: `KeyError: 'dolphin3'` æˆ–æ¨¡å‹æœªæ‰¾åˆ°
**åŸå› **: æ¨¡å‹åç§°ä¸åŒ¹é…
**è§£å†³**:
```bash
# æŸ¥çœ‹ Ollama ä¸­çš„å®é™…æ¨¡å‹å
ollama list

# ä¿®æ”¹ .env ä¸­çš„ GENERATOR_MODEL ä¸ºå®é™…åç§°
# ä¾‹å¦‚: GENERATOR_MODEL=dolphin3:latest
```

### é—®é¢˜ 2: Judge ä¸€ç›´è¿”å› 0.5 (è§£æå¤±è´¥)
**åŸå› **: DeepSeek-R1 è¾“å‡ºæ ¼å¼ä¸ç¬¦åˆé¢„æœŸ
**è§£å†³**:
1. æ£€æŸ¥ `examples/safety/eval.py` ä¸­çš„ `clean_deepseek_output()` å‡½æ•°
2. ä¸´æ—¶å¯ç”¨ debug è¾“å‡ºæŸ¥çœ‹åŸå§‹å“åº”:
```python
# åœ¨ eval.py çš„ eval() å‡½æ•°ä¸­æ·»åŠ 
print(f"DEBUG Raw Response: {response}")
print(f"DEBUG Clean Response: {clean_response}")
```

### é—®é¢˜ 3: Ollama å†…å­˜ä¸è¶³
**è§£å†³**:
```bash
# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
ollama pull qwen2.5:7b
# ä¿®æ”¹ .env ä¸º LLM_TYPE=qwen2.5:7b
```

### é—®é¢˜ 4: ç”Ÿæˆé€Ÿåº¦å¤ªæ…¢
**è§£å†³**:
1. å‡å°‘ `--population_size` åˆ° 10
2. å‡å°‘ `--max_time` åˆ° "01:00:00"
3. ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹å¦‚ `llama3.2:3b`

---

## ğŸ“ æ¨¡å‹é€‰æ‹©å»ºè®®

æ ¹æ®è®ºæ–‡è¦æ±‚å’Œä½ çš„ç¡¬ä»¶é…ç½®ï¼š

| è§’è‰² | æ¨èæ¨¡å‹ | åŸå›  |
|-----|---------|------|
| **Generator** | `dolphin3:latest` | æ“…é•¿æŒ‡ä»¤éµå¾ªï¼Œç”Ÿæˆå¤šæ ·åŒ–æ”»å‡» |
| **SUT (è¢«æµ‹ç³»ç»Ÿ)** | `deepseek-r1:7b` | è®ºæ–‡æµ‹è¯•ç›®æ ‡ï¼Œ7B å¹³è¡¡æ€§èƒ½ |
| **Judge** | `deepseek-r1:7b` | éœ€è¦å¼ºæ¨ç†èƒ½åŠ›åˆ¤æ–­å®‰å…¨æ€§ |
| **Fitness** | `qwen2.5:7b` (å¯é€‰) | å¦‚æœ DeepSeek å¤ªæ…¢å¯æ›¿æ¢ |

---

## ğŸ” éªŒè¯é…ç½®æ­£ç¡®æ€§

è¿è¡Œä»¥ä¸‹å‘½ä»¤æ£€æŸ¥æ‰€æœ‰é…ç½®ï¼š
```bash
cd /Users/panjiaying/Documents/Projects/STELLAR

# æ£€æŸ¥ç¯å¢ƒå˜é‡
cat .env

# æ£€æŸ¥ LLMType å®šä¹‰
grep -A 5 "class LLMType" llm/llms.py

# æ£€æŸ¥ LOCAL_MODELS
grep -A 10 "LOCAL_MODELS" llm/llms.py

# æµ‹è¯• Ollama è°ƒç”¨
python llm/call_ollama.py
```

---

## ğŸ“š ä¸‹ä¸€æ­¥

1. âœ… ç¡®è®¤ Ollama æœåŠ¡è¿è¡Œ
2. âœ… éªŒè¯æ¨¡å‹å·²ä¸‹è½½
3. âœ… è¿è¡Œ `./run_safety_local.sh`
4. ğŸ“Š ç›‘æ§ `results/` ç›®å½•è¾“å‡º
5. ğŸ› å¦‚æœ‰æŠ¥é”™ï¼Œå‚è€ƒä¸Šæ–¹å¸¸è§é—®é¢˜æ’æŸ¥

å¦‚æœé‡åˆ°å…¶ä»–é—®é¢˜ï¼Œæ£€æŸ¥ `log.txt` æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯ã€‚
